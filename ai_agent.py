import streamlit as st
import os
import google.generativeai as genai
from langchain_community.utilities import SQLDatabase
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.agent_toolkits import create_sql_agent
from fpdf import FPDF
import io

# Naya Import tareeka (ImportError fix karne ke liye)
try:
    from langchain_chroma import Chroma
except ImportError:
    from langchain_community.vectorstores import Chroma

# 1. Configuration & Key Setup
gemini_key = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=gemini_key)

# Database Connection (SQLite file must be in your repo)
MYSQL_URL = "sqlite:///historical_trends.db"
db = SQLDatabase.from_uri(MYSQL_URL)

# 2. Multi-Agent LLM & Embeddings Setup
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

# Safe Vector DB Initialization
# Agar chroma_db folder nahi hai toh app crash nahi hogi
if os.path.exists("./chroma_db"):
    vector_db = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)
else:
    vector_db = None

# 3. Create the SQL AI Agent
agent_executor = create_sql_agent(
    llm=llm, 
    db=db, 
    agent_type="zero-shot-react-description", 
    verbose=True
)

# 4. Executive PDF Generator Tool
def generate_pdf_report(analysis_text):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", 'B', 16)
    pdf.cell(200, 10, txt="UPSC DATA ANALYST - EXECUTIVE BRIEF", ln=True, align='C')
    pdf.ln(10)
    pdf.set_font("Arial", size=12)
    clean_text = analysis_text.encode('latin-1', 'replace').decode('latin-1')
    pdf.multi_cell(0, 10, txt=clean_text)
    pdf.ln(20)
    pdf.set_font("Arial", 'I', 8)
    pdf.cell(0, 10, txt="Generated by AI Data Analyst Team", align='R')
    return pdf.output(dest='S').encode('latin-1')

# 5. Hybrid Analyst Logic (SQL + PDF Context)
def ask_data_analyst(question):
    try:
        # Step A: Data Engineer Agent fetches SQL data
        raw_data = agent_executor.invoke({"input": question})
        fetched_info = raw_data['output']
        
        pdf_info = ""
        # Step B: PDF Retrieval (Sirf agar database ready ho)
        if vector_db is not None:
            docs = vector_db.similarity_search(question, k=2)
            if docs:
                pdf_info = "\n\n**Insights from Official Reports:**\n" + docs[0].page_content

        # Step C: Executive Analyst Agent creates the brief
        summary_prompt = f"""
        As a Senior UPSC Consultant, analyze this combined data:
        SQL Data: {fetched_info}
        Report Context: {pdf_info}
        
        Provide an 'Executive Brief' including:
        1. Key Findings (Bullet points)
        2. Proactive Insights (For aspirants)
        3. Potential Anomalies (If any)
        """
        executive_brief = llm.invoke(summary_prompt).content
        
        full_response = f"{fetched_info}{pdf_info}\n\n---\n### üìä Executive Brief\n{executive_brief}"
        return full_response
        
    except Exception as e:
        if "429" in str(e):
            return "‚ùå Quota Exhausted! Please wait 1 minute."
        return f"‚ùå Error: {e}"
